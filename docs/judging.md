# PlotSense Hackathon Judging Guide

This document provides the criteria and scoring system for evaluating submissions.

## 1. Overview

Submissions are divided into two tracks:

- **ML Track:** Focus on notebooks, analysis, visualizations, and AI features.  
- **Dev Track:** Focus on code quality, technical documentation, tests, and contributions to PlotSense modules.

Judges will use GitHub Pages (`docs/submissions_index.md`) to access each submission.

## 2. Scoring Criteria

| Criterion | Weight | Description |
|-----------|--------|-------------|
| **Completeness** | 25% | All required files/folders present (checked automatically by CI). |
| **Functionality** | 25% | Notebooks run without errors (ML) or code/tests pass (Dev). |
| **Creativity / Innovation** | 20% | Novel approaches, clever visualizations, or algorithmic improvements. |
| **Clarity / Documentation** | 15% | Clear README, comments, and explanations of work. |
| **Presentation / Video** | 15% | Video demonstrates submission effectively and is easy to follow. |

> Total score = 100%

## 3. Review Process

1. Open **GitHub Pages submissions index**:  
https://plotsenseai.github.io/PlotSenseAI-Hackathon-September-2025

2. Navigate to each team’s PR and folder  
3. Verify:
- CI status badges: ✅ / ❌  
- Submission completeness  
- Test/notebook execution  
- Video link
4. Score each criterion (0–5 or 0–10 scale) and multiply by weight  
5. Record scores in **judge spreadsheet or Google Form**

## 4. Notes for Judges

- Missing files automatically lower completeness score  
- Minor notebook errors: judge may adjust Functionality score  
- Dev track: ensure tests in `tests/` pass  
- Encourage participants’ innovation and creativity

## 5. Optional Tie-Breakers

- Extra functionality or bonus features beyond the template  
- Clean, reusable code or modular notebook design  
- Innovative visualizations or AI-driven insights

## 6. Reporting

- Scores are collected centrally  
- Total scores determine winner per track  
- CI reports and `submission_report.md` artifacts provide objective verification
